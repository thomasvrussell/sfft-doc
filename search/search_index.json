{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to Documentation for SFFT.</p>"},{"location":"QA/","title":"Q &amp; A","text":""},{"location":"QA/#which-image-is-convolved","title":"Which image is convolved?","text":"<p>Answer</p> <p>There is a universal argument named <code>-ForceConv</code> to control the direction of image subtraction, which works on all image subtraction modules in sfft.</p> <ul> <li> <p><code>-ForceConv = AUTO</code> means sfft will determine the direction of image subtraction automatically according to the estimated FWHM of reference image and science image. The image which has smaller FWHM will be convolved in the image subtraction to avoid deconvolution. After comparing the FWHM, <code>AUTO</code> actually becomes either <code>REF</code> or <code>SCI</code> (see below). </p> <p>One can get to know which image is eventually convolved in image subtraction from the primary header of the output difference image (see the FITS keyword <code>CONVD</code>). This mode does not supported in the Customized module <code>sfft.CustomizedPacket</code>.</p> </li> <li> <p><code>-ForceConv = REF</code> means sfft will convolve the reference image and DIFF = SCI - Convolved_REF. As a result, the psf and flux zero-point of difference image is consistent with the unconvolved image, i.e., the science image.</p> </li> <li> <p><code>-ForceConv = SCI</code> means sfft will convolve the reference image and DIFF = Convolved_SCI - REF. Consequently, the psf and flux zero-point of difference image is consistent with the unconvolved image, i.e., the reference image.</p> </li> </ul> <p>One can perform PSF / Aperture photometry on the transients on difference image as if it is an object living in the science (reference) image when <code>REF</code> (<code>SCI</code>) is convolved: using the same psf model / aperture and magnitude zeropoint.</p> <p>With our convention, a transient on science image is always a positive signal on difference image whatever <code>-ForceConv</code> is.</p>"},{"location":"QA/#backward-compatiablity","title":"Backward compatiablity?","text":"<p>Answer</p> <p>We have tried our best to ensure the backward compatiablity, however, the rule was sometimes overrided in the development of sfft, e.g., some arguments might be deprecated in higher version of sfft. Users might get errors when they use old scripts but update sfft to a higher version. To solve the problem, I have been maintaining the test scripts on Github to make sure they can always work for the lastest version of sfft. You can also find the change log of arguments in the test scripts. </p>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p>The version <code>sfft v1.6</code> is developed during the NASA GPU Hackathon 2024 as part of the pipeline optimization efforts for the Roman Supernova PIT team. The valuable support and insightful suggestions from our team members and Hackathon mentors are essential for the improvements in this version of SFFT. </p> <p>I would like to specifically acknowledge the contributions of the following team members: Lauren Aldoroty (Duke), Robert Knop (LBNL), Shu Liu (Pitt), and Michael Wood-Vasey (Pitt). Additionally, I am grateful for the guidance provided by our mentors, Marcus Manos and Lucas Erlandson from NVIDIA.</p>"},{"location":"citing/","title":"Citing","text":"<p>[1] Image Subtraction in Fourier Space<sup>1</sup>.  Hu et al. 2022, The Astrophysical Journal, 936, 157  See Arxiv Link, ADS Link and Related DOI: 10.3847/1538-4357/ac7394</p> <p>[2] Differencing and Coadding JWST Images with Matched Point-spread Function<sup>2</sup>.  Hu &amp; Wang 2024, The Astronomical Journal, 167, 231  See Arxiv Link, ADS Link and Related DOI: 10.3847/1538-3881/ad36cb</p> <ol> <li> <p>The first publication of SFFT introduced the fundamental methodology behind the SFFT approach.\u00a0\u21a9</p> </li> <li> <p>The second publication of SFFT introduced several adaptations and improvements. We incorporated kernel regularization into SFFT and extended the method to be fully compatible with ZOGY's statistically closed-form framework. This hybrid approach preserves the general workflow of ZOGY while adding image-matching refinements using the SFFT code, making it an optimal subtraction engine for space telescopes such as JWST/NIRCam and Roman.\u00a0\u21a9</p> </li> </ol>"},{"location":"contact/","title":"Contact","text":"<p>If you have any question or recommendation about the SFFT, feel free to contact the authors!</p> <p>Contact</p> <p>Dr. Lei Hu Postdoctoral Research Associate | McWilliams Center for Cosmology Carnegie Mellon University | Pittsburgh, PA | USA leihu@andrew.cmu.edu or astroleihu@gmail.com</p> <p>Prof. Lifan Wang Professor | Department of Physics &amp; Astronomy  Texas A&amp;M University | College Station, TX | USA lifan@tamu.edu</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#sfft-installation","title":"SFFT Installation","text":"<p>To install the latest stable version of sfft from PyPI: [recommended]</p> Latest <pre><code>pip install sfft\n</code></pre> <p>One can also install sfft from GitHub: <pre><code>git clone https://github.com/thomasvrussell/sfft.git\n</code></pre> <pre><code>pip install .\n</code></pre> Both will automatically install compatible versions of python dependencies.</p> <p>Tip</p> <p>PyPI/GitHub installation does not include the setup of GPU backend.</p>"},{"location":"installation/#enable-gpu-backend","title":"Enable GPU backend","text":"<p>SFFT supports both CPU (Numpy) backend and GPU (Cupy) backend. To enable the GPU backend, users need to further install CuPy according to their CUDA version. Note this backend requires GPU device(s) with double-precision support.</p> <ul> <li> <p>CUDA 12: e.g., enable the CuPy backend for CUDA 12.0 via <pre><code>pip install cupy-cuda12x\n</code></pre></p> </li> <li> <p>CUDA 11: e.g., enable the CuPy backend for CUDA 11.5 via <pre><code>pip install cupy-cuda115\n</code></pre></p> </li> <li> <p>CUDA 10: e.g., enable the CuPy backend for CUDA 10.1 via <pre><code>pip install cupy-cuda101\n</code></pre></p> </li> </ul> <p>Remarks</p> <p>There was a PyCUDA backend in sfft but now deprecated since v1.4.0. For sfft &lt; v1.4.0, PyCUDA backend was preserved as it consumes less GPU memory. However, the CuPy backend is now better implemented for GPU memory allocation, making the PyCUDA backend no longer useful.</p>"},{"location":"installation/#astromatic-dependencies","title":"AstrOmatic Dependencies","text":"<p>You need further to install additional AstrOmatic software for sfft.</p> <ul> <li> <p>SExtractor: SExtractor from AstrOmatic is required for SFFT preprocessing, as it allows SFFT to determine an appropriate pixel mask for the input image pair before performing image subtraction. This step is critical for achieving more accurate parameter solutions. <pre><code>conda install -c conda-forge astromatic-source-extractor\n</code></pre></p> <p>Tip</p> <p>We have wrapped SExtractor into a Python module, <code>sfft.utils.pyAstroMatic.PYSEx</code>, enabling users to trigger SExtractor directly within Python. Use <code>help(sfft.utils.pyAstroMatic.PYSEx)</code> for more details.</p> </li> <li> <p>SWarp (optional): SWarp from AstrOmatic is not required for sfft subtraction itself. However, it is normally useful to align the input image-pair before image subtraction by SWarp. <pre><code>conda install -c conda-forge astromatic-swarp\n</code></pre></p> <p>Tip</p> <p>We have additionally wrapped SWarp into a Python module <code>sfft.utils.pyAstroMatic.PYSWarp</code> so that you can align images in a more Pythonic way. Use <code>help(sfft.utils.pyAstroMatic.PYSWarp)</code> for more details.</p> </li> </ul>"},{"location":"issue/","title":"Issues","text":"<p>Tip</p> <p>Please report bugs on Github: SFFT Github Issues</p>"},{"location":"issue/#installation-issues","title":"Installation issues","text":"<p>Issue</p> <p>If your Python environment already has some version of <code>llvmlite</code> (a package required by NumPy backend) before installing sfft. Sometimes the <code>setup.py</code> in sfft cannot properly update llvmlite to the desired version, then you may get errors related to <code>Numba</code> or <code>llvmlite</code>. You can manually install llvmlite by: <pre><code>pip install llvmlite==0.36.0 --ignore-installed\n</code></pre></p>"},{"location":"new/","title":"What's New","text":""},{"location":"new/#2024","title":"2024","text":"<ul> <li> <p>[Lei, Sep 23, 2024] New release <code>sfft v1.6.1</code>: add PureCupy modules to directly handle GPU arrays as inputs/outputs. Most improvements were developed during the NASA GPU Hackathon 2024.</p> </li> <li> <p>[Lei, Sep 17, 2024] We are developing SFFT in NASA GPU Hackathon 2024 as part of the pipeline optimization efforts for the Roman Supernova PIT team.</p> </li> <li> <p>[Lei, Mar 9, 2024] New release <code>sfft v1.5.0</code> that added B-Spline SFFT as a main function.</p> </li> <li> <p>[Lei, Jan 9, 2024] New release <code>sfft v1.4.2+</code> that can support Python 3.10! </p> </li> </ul>"},{"location":"new/#2023","title":"2023","text":"<ul> <li>[Lei, Dec 4, 2023] New tutorial jupyter notebooks are available now, find them in test directories! </li> </ul>"},{"location":"new/#2022","title":"2022","text":"<ul> <li> <p>[Lei, Nov 9, 2022] A warning for users: As scikit-image has changed something in its function of hough detection since version 0.19.0, I recently found that the source selection in sfft will be affected by this upgrade. For the time being I would recommend users to install <code>0.16.2 &lt;= scikit-image &lt;= 0.18.3</code>. I may add a constrain on scikit-image version in sfft 1.3.5. </p> </li> <li> <p>[Lei, Oct 25, 2022] A warning message about the usage of <code>sfft.MultiEasySparsePacket</code> and <code>sfft.MultiEasyCrowdedPacket</code> is added in the related test scripts. </p> </li> <li> <p>[Lei, Aug 19, 2022] The preprocessing in sparse-flavor-sfft is refined using an additional rejection of mild varaibles since version 1.3.0. </p> </li> <li> <p>[Lei, May 24, 2022] The sfft is now optimized for multiple tasks since version 1.1.0. </p> </li> <li> <p>[Lei, May 24, 2022] A few argument-names have been changed since version <code>sfft v1.1.0</code>, please see the test scripts. </p> </li> <li> <p>[Lei, May 24, 2022] Locking file is removed since <code>sfft v1.1.0</code>, as I found it unreliable in our tests, i.e., -GLockFile is removed. </p> </li> <li> <p>[Lei, May 24, 2022] The trial subtraction for refinement is removed since <code>sfft v1.1.0</code>. However, I add a post-subtraction check to search anomalies on the difference image using the same logic. One can feed the coordinates of the anomalies to sfft again as Prior-Banned sources to refine the subtraction (see <code>-XY_PriorBan</code> in <code>sfft.MultiEasySparsePacket</code>). </p> </li> </ul>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#about-sfft","title":"About SFFT","text":"<p>Saccadic Fast Fourier Transform (SFFT) is an algorithm for astronomical image subtraction in Fourier space (Hu et al., 2022). SFFT brings about a remarkable improvement of computational performance of an order of magnitude compared to other published image subtraction codes.</p> <p></p> <p>SFFT method is the transient detection engine for several ongoing time-domain programs, including the DESIRT survey based on DECam &amp; DESI, the DECam GW-MMADS Survey for GW Follow-ups and the JWST Cycle 3 Archival program AR 5965. SFFT is also the core engine for the differential photometry pipeline of the Roman Supernova PIT.</p>"},{"location":"overview/#sfft-vs-others","title":"SFFT vs. Others","text":"<p>To get a clear picture of our method, we summarize a variety of features from different perspectives for SFFT and other existing image subtraction methods:</p> <p></p> <p>Remarks</p> <p>The table above only reflects the status of the SFFT method at the time of its initial publication in 2022. In Hu et al. (2024), we introduced kernel regularization into SFFT and implemented it in our software. </p> <p>Additionally, to leverage the advantages of the ZOGY approach, we extended the SFFT method to be fully compatible with ZOGY's statistically closed-form framework. This hybrid method retains the general workflow of ZOGY while incorporating image-matching refinements using the SFFT code. This adaptation makes SFFT an optimal subtraction engine for space telescopes, such as JWST/NIRCam and Roman.</p>"},{"location":"overview/#publications-using-sfft","title":"Publications using SFFT","text":"<p>See ADS Library: https://ui.adsabs.harvard.edu/public-libraries/lc4tiTR_T--92f9k0YrRQg</p>"},{"location":"todo/","title":"Todo List","text":""},{"location":"todo/#2022","title":"2022","text":"<ul> <li> <p>[Lei, Nov 11, 2022] The total GPU memory usage is only optimized for KerPolyOrder = 2 &amp; BGPolyOrder = 2, I will extend the optimization to other cases ASAP! In fact, I believe there is ample space for reducing the total GPU usage and I will explore it. [FINISHED]</p> </li> <li> <p>[Lei, Nov 11, 2022] I will allows users to disable the hough detection for preprocessing when there are too few sources in the field in the next version sfft v1.3.5. </p> </li> <li> <p>[Lei, Nov 9, 2022] Add a verbose argument for sfft so that users can get more clean printed messages. [FINISHED]</p> </li> <li> <p>[Lei, Nov 9, 2022] Test if we can use sep to replace SExtractor in preprocessing to make sfft more Pythonic.  </p> </li> <li> <p>[Lei, July 6, 2022] Incorporate the separate functions for spline form sfft into the unified sfft functions. Note that only Numpy backend is currently available and the spline form is very memory-consuming. [FINISHED]</p> </li> <li> <p>[Lei, May 24, 2022] Write a detailed documentation for sfft! [FINISHED]</p> </li> <li> <p>[Lei, May 24, 2022] We notice that SExtractor may have been called to perform astrometric calibration before image subtraction. It is definitely not wise to run SExtractor again in sfft, I need to develop a module which allows users to feed SExtractor products as inputs of sfft, which will significantly reduce the preprocessing time in sfft. </p> </li> <li> <p>[Lei, May 24, 2022] The multiprocessing mode is expected to accomondate multiple GPU devices, however, the function has not tested on such a multi-GPUs platform. [FINISHED]</p> </li> <li> <p>[Lei, May 20, 2022] Add a function for optimizing sfft on a given computing platform with multiple CPU threading and one/multiple GPU card(s). This would be very useful to reduce the overall time cost when users have a large set of image-pairs to be processed simultaneously. [FINISHED]</p> </li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#quick-start","title":"Quick Start","text":"<p>We have provided several examples in the test directory of our GitHub repository to help you quickly get acquainted with the main functions of our software.</p>"},{"location":"tutorials/#sparse-field-flavor-sfft","title":"Sparse Field Flavor SFFT","text":"<p>The sparse field flavor is the most common mode. It works well when isolated sources are dominated/sufficient in the field. Get started with Example for Sparse Field Flavor SFFT. </p> <p>In this example, we use the module <code>sfft.EasySparsePacket</code> to perform image subtraction for CTIO-4m DECam observations. For more details on module usage, refer to <code>help(sfft.EasySparsePacket)</code>.</p>"},{"location":"tutorials/#crowded-field-flavor-sfft","title":"Crowded Field Flavor SFFT","text":"<p>The crowded field flavor is designed for extreme cases where sources are typically highly blended in the field. Get started with Example for Crowded Field Flavor SFFT. </p> <p>In this example, we use the module <code>sfft.EasyCrowdedPacket</code> to perform image subtraction for ZTF M31 observations. For more details on module usage, refer to <code>help(sfft.EasyCrowdedPacket)</code>.</p> <p>Remarks</p> <ul> <li> <p>The two flavors SFFT actually follow the same routine for image subtraction and differ only in ways of masking the data for kernel determination.</p> </li> <li> <p>Proper image-masking is required by SFFT to identify the pixels that cannot be correctly modeled (hereafter, distraction pixels), e.g., saturated sources, casual cosmic rays and moving objects, bad CCD pixels, optical ghosts, and even the variable objects and transients themselves. The pre-subtraction processing for image-masking is referred to as preprocessing in sfft.</p> </li> <li> <p>Our software provides a generic and robust function to perform preprocessing of the data, which has been extensively tested with data from various transient surveys. When you run Crowded-flavor sfft and Sparse-flavor sfft, sfft actually performs the generic preprocessing for image-masking and do the sfft subtraction subsequently. </p> </li> </ul> <p>Details</p> <p>More specificially, the built-in preprocessing in sfft consists of two steps: (I) identify the distraction pixels in the input image-pair; (II) create the masked version of the input image-pair via replacing the identified distraction pixels by proper flux values. </p> <p>In Sparse-flavor sfft, we designed a source-selection based on SExtractor catalogs and identify the unselected regions as distraction pixels. Given that the input images are required to be sky-subtracted in Sparse-flavor sfft, we simply replace the distraction pixels by zeros; </p> <p>In Crowded-flavor sfft, we only identify the pixels contaminated by saturated sources as distraction pixels using SExtractor, and then replace the distraction pixels by local background flux. </p>"},{"location":"tutorials/#sfft-on-multiple-tasks","title":"SFFT on Multiple Tasks","text":"<p>We also developed modules to optimize the overall computing performance of Sparse-flavor sfft and Crowded-flavor sfft for the cases when you need to deal with multiple tasks simultaneously. Get started with Examples for Mult-Task SFFT. Note that the multiprocessing mode ONLY support the CuPy backend. </p> <p>We use the module <code>sfft.MultiEasySparsePacket</code> in Multi-Task Example for Sparse-flavor SFFT and <code>sfft.MultiEasyCrowdedPacket</code> in Multi-Task Example for Crowded-flavor SFFT to conduct image subtraction on a set of image pairs, respectively.</p> <p>Details</p> <p>In a particular time-domain survey, one may need to process a large set of image-pairs simultaneously. Assume that you have Nt tasks which should be processed by a computing platform with Nc CPU threads and Ng GPU devices. Generally, Nt &gt;&gt; Ng and Nc &gt;&gt; Ng. E.g.,</p> <pre><code>Nt = 61 (A DECam exposure with CCDs)\nNc = 40 (A CPU with 40 threads)\nNg = 1 (A Tesla A100 available)\n</code></pre> <p>Note that we generally need to avoid multiple tasks using one GPU at the same time (GPU out-of-memory issue). That is to say, we CANNOT simply trigger a set of sfft functions (e.g., <code>sfft.EasySparsePacket</code>) to process a large set of image-pairs simultaneously. </p> <p>The SFFT modules are designed to handle multiple tasks by parallelizing CPU-intensive preprocessing through multiprocessing on CPU, while running the GPU-intensive SFFT subtraction sequentially on each available GPU device.</p>"},{"location":"tutorials/#preparations-before-sfft","title":"Preparations before SFFT","text":"<p>Sky subtraction is required for the Sparse Field Flavor of SFFT, while image alignment is necessary for both flavors of SFFT. SFFT provides convenient modules to assist users in performing both sky subtraction and image alignment, see Example for SFFT preparation.</p> <ul> <li> <p>Use SExtractor to subtract the sky background, see Example for Sky Subtraction using module <code>sfft.utils.SExSkySubtract</code>. </p> </li> <li> <p>Use SWarp to align reference image and science image, see Example for Image Alignment using module <code>sfft.utils.pyAstroMatic.PYSWarp</code>. </p> </li> </ul>"},{"location":"tutorials/#noise-decorrelation-after-sfft","title":"Noise Decorrelation after SFFT","text":"<p>SFFT also provided a decorrelation module to whiten the background noise of the SFFT difference image, see Example for Difference Noise Decorrelation.</p> <p>In this example, we use the module <code>sfft.utils.DeCorrelationCalculator</code> to whiten the background noise on difference image. The test difference image is generated from sfft image subtraction between a coadded reference image and a coadded science image, each stacked from 5 DECam individual observations with PSF homogenization using sfft. The toolkit can be also applied to whiten a coadded image as long as convolution is involved in the stacking process.</p>"},{"location":"tutorials/#customized-masking","title":"Customized masking","text":"<p>SFFT also allows users to feed their own image-masking to replace the generic preprocessing in Sparse-flavor sfft or Crowded-flavor sfft. Get started with Example for Customized SFFT. </p> <p>In this example, we use the module <code>sfft.CustomizedPacket</code> to perform image subtraction for ZTF-M31 observations with given image mask. For more details on module usage, refer to <code>help(sfft.CustomizedPacket)</code>.</p> <p>Tip</p> <p>The module focuses exclusively on the subtraction process, giving users a sense of the lightning-fast speed of SFFT subtraction on GPU devices!</p> <p>Tip</p> <p>If you are using GPU backends and processing a queue of observations, the first iteration of SFFT subtraction may be slow due to CuPy compilation. However, the runtime stabilizes after the initial run. As observed in the previous test, the GPU warm-up phase can be quite slow. Fortunately, this issue can be easily mitigated by running a trivial subtraction (even on simple images) beforehand, allowing the pipeline to warm up and be ready for subsequent observations.</p> <p>Remarks</p> <p>The built-in preprocessing in SFFT, based on SExtractor, is designed to provide a generic yet conservative approach that can adapt to a wide variety of imaging data. However, in contrast to the high speed of the image subtraction, the computing performance of the built-in preprocessing is considerably less efficient, taking roughly 10 times longer. For specific time-domain programs, we believe there is significant potential for optimizing the computing overhead associated with preprocessing. Below are two suggestions that may help users incorporate SFFT more efficiently into their pipeline:</p> <ul> <li> <p>For Sparse-flavor SFFT, the built-in preprocessing performs source selection based on SExtractor catalogs and then creates masked images for subsequent subtraction. To optimize the overall computational cost of the pipeline, users can leverage the SExtractor products generated in earlier stage (e.g., astrometric calibration) for source selection in SFFT. This approach is much faster than running SExtractor again, as it avoids repeated photometry and significantly reduces computing time.</p> </li> <li> <p>For Crowded-flavor SFFT, the built-in preprocessing only masks saturation-contaminated pixels using SExtractor. However, when data quality masks are available for the observed imaging data in a survey program, users can identify invalid pixels using those masks and replace them with the local background. This allows the built-in preprocessing to be entirely skipped, streamlining the workflow.</p> </li> </ul> <p>We encourage users to design dedicated image-masking strategies for their survey programs to unleash the great power of sfft subtraction!</p>"}]}